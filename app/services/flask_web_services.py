"""
Flask WebæœåŠ¡å™¨ - SSEæµå¼è¾“å‡ºç‰ˆ
æ”¯æŒServer-Sent Eventså®æ—¶æ¨é€åˆ†æè¿›åº¦å’Œç»“æœ
"""

from flask import Flask, request, jsonify, render_template_string, session, redirect, url_for, Response
from flask_cors import CORS
import logging
import json
import threading
from datetime import datetime
import os
import sys
import math
import numpy as np
from concurrent.futures import ThreadPoolExecutor
from functools import wraps
import secrets
from queue import Queue, Empty

# å¯¼å…¥æˆ‘ä»¬çš„åˆ†æå™¨
try:
    from app.services.analyzer import WebStockAnalyzer
except ImportError:
    print("âŒ æ— æ³•å¯¼å…¥ web_stock_analyzer.py")
    print("è¯·ç¡®ä¿ web_stock_analyzer.py æ–‡ä»¶å­˜åœ¨äºåŒä¸€ç›®å½•ä¸‹")
    sys.exit(1)

# åˆ›å»ºFlaskåº”ç”¨
app = Flask(__name__)
CORS(app)  # å…è®¸è·¨åŸŸè¯·æ±‚

# é«˜å¹¶å‘ä¼˜åŒ–é…ç½®
app.config['JSONIFY_PRETTYPRINT_REGULAR'] = False
app.config['JSON_SORT_KEYS'] = False

# ç”Ÿæˆéšæœºçš„SECRET_KEY
app.secret_key = secrets.token_hex(32)

# å…¨å±€å˜é‡
analyzer = None
analysis_tasks = {}  # å­˜å‚¨åˆ†æä»»åŠ¡çŠ¶æ€
task_results = {}   # å­˜å‚¨ä»»åŠ¡ç»“æœ
task_lock = threading.Lock()
sse_clients = {}    # å­˜å‚¨SSEå®¢æˆ·ç«¯è¿æ¥
sse_lock = threading.Lock()

# çº¿ç¨‹æ± ç”¨äºå¹¶å‘å¤„ç†
executor = ThreadPoolExecutor(max_workers=4)

# é…ç½®æ—¥å¿— - åªè¾“å‡ºåˆ°å‘½ä»¤è¡Œ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class SSEManager:
    """SSEè¿æ¥ç®¡ç†å™¨"""
    
    def __init__(self):
        self.clients = {}
        self.lock = threading.Lock()
    
    def add_client(self, client_id, queue):
        """æ·»åŠ SSEå®¢æˆ·ç«¯"""
        with self.lock:
            self.clients[client_id] = queue
            logger.info(f"SSEå®¢æˆ·ç«¯è¿æ¥: {client_id}")
    
    def remove_client(self, client_id):
        """ç§»é™¤SSEå®¢æˆ·ç«¯"""
        with self.lock:
            if client_id in self.clients:
                del self.clients[client_id]
                logger.info(f"SSEå®¢æˆ·ç«¯æ–­å¼€: {client_id}")
    
    def send_to_client(self, client_id, event_type, data):
        """å‘ç‰¹å®šå®¢æˆ·ç«¯å‘é€æ¶ˆæ¯"""
        with self.lock:
            if client_id in self.clients:
                try:
                    # æ¸…ç†æ•°æ®ç¡®ä¿JSONå¯åºåˆ—åŒ–
                    cleaned_data = clean_data_for_json(data)
                    message = {
                        'event': event_type,
                        'data': cleaned_data,
                        'timestamp': datetime.now().isoformat()
                    }
                    self.clients[client_id].put(message, block=False)
                    return True
                except Exception as e:
                    logger.error(f"SSEæ¶ˆæ¯å‘é€å¤±è´¥: {e}")
                    return False
            return False
    
    def broadcast(self, event_type, data):
        """å¹¿æ’­æ¶ˆæ¯ç»™æ‰€æœ‰å®¢æˆ·ç«¯"""
        with self.lock:
            # æ¸…ç†æ•°æ®ç¡®ä¿JSONå¯åºåˆ—åŒ–
            cleaned_data = clean_data_for_json(data)
            message = {
                'event': event_type,
                'data': cleaned_data,
                'timestamp': datetime.now().isoformat()
            }
            
            dead_clients = []
            for client_id, queue in self.clients.items():
                try:
                    queue.put(message, block=False)
                except Exception as e:
                    logger.error(f"SSEå¹¿æ’­å¤±è´¥ç»™å®¢æˆ·ç«¯ {client_id}: {e}")
                    dead_clients.append(client_id)
            
            # æ¸…ç†æ­»è¿æ¥
            for client_id in dead_clients:
                del self.clients[client_id]

# å…¨å±€SSEç®¡ç†å™¨
sse_manager = SSEManager()

def clean_data_for_json(obj):
    """æ¸…ç†æ•°æ®ä¸­çš„NaNã€Infinityã€æ—¥æœŸç­‰æ— æ•ˆå€¼ï¼Œä½¿å…¶èƒ½å¤Ÿæ­£ç¡®åºåˆ—åŒ–ä¸ºJSON"""
    import pandas as pd
    from datetime import datetime, date, time
    
    if isinstance(obj, dict):
        return {key: clean_data_for_json(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [clean_data_for_json(item) for item in obj]
    elif isinstance(obj, tuple):
        return [clean_data_for_json(item) for item in obj]
    elif isinstance(obj, (int, float)):
        if math.isnan(obj):
            return None
        elif math.isinf(obj):
            return None
        else:
            return obj
    elif isinstance(obj, np.ndarray):
        return clean_data_for_json(obj.tolist())
    elif isinstance(obj, (np.integer, np.floating)):
        if np.isnan(obj):
            return None
        elif np.isinf(obj):
            return None
        else:
            return obj.item()
    elif isinstance(obj, (datetime, date)):
        return obj.isoformat() if hasattr(obj, 'isoformat') else str(obj)
    elif isinstance(obj, time):
        return obj.isoformat()
    elif isinstance(obj, pd.Timestamp):
        return obj.isoformat()
    elif isinstance(obj, pd.NaT.__class__):
        return None
    elif pd.isna(obj):
        return None
    elif hasattr(obj, 'to_dict'):  # DataFrameæˆ–Series
        try:
            return clean_data_for_json(obj.to_dict())
        except:
            return str(obj)
    elif hasattr(obj, 'item'):  # numpyæ ‡é‡
        try:
            return clean_data_for_json(obj.item())
        except:
            return str(obj)
    elif obj is None:
        return None
    elif isinstance(obj, (str, bool)):
        return obj
    else:
        # å¯¹äºå…¶ä»–ä¸å¯åºåˆ—åŒ–çš„å¯¹è±¡ï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²
        try:
            # å°è¯•ç›´æ¥åºåˆ—åŒ–æµ‹è¯•
            json.dumps(obj)
            return obj
        except (TypeError, ValueError):
            return str(obj)

def check_auth_config():
    """æ£€æŸ¥é‰´æƒé…ç½®"""
    if not analyzer:
        return False, {}
    
    web_auth_config = analyzer.config.get('web_auth', {})
    return web_auth_config.get('enabled', False), web_auth_config

def require_auth(f):
    """é‰´æƒè£…é¥°å™¨"""
    @wraps(f)
    def decorated_function(*args, **kwargs):
        auth_enabled, auth_config = check_auth_config()
        
        if not auth_enabled:
            return f(*args, **kwargs)
        
        # æ£€æŸ¥sessionä¸­æ˜¯å¦å·²è®¤è¯
        if session.get('authenticated'):
            # æ£€æŸ¥sessionæ˜¯å¦è¿‡æœŸ
            login_time = session.get('login_time')
            if login_time:
                session_timeout = auth_config.get('session_timeout', 3600)
                if (datetime.now() - datetime.fromisoformat(login_time)).total_seconds() < session_timeout:
                    return f(*args, **kwargs)
                else:
                    session.pop('authenticated', None)
                    session.pop('login_time', None)
        
        return redirect(url_for('login'))
    
    return decorated_function

def init_analyzer():
    """åˆå§‹åŒ–åˆ†æå™¨"""
    global analyzer
    try:
        logger.info("æ­£åœ¨åˆå§‹åŒ–WebStockAnalyzer...")
        analyzer = WebStockAnalyzer()
        logger.info("âœ… WebStockAnalyzeråˆå§‹åŒ–æˆåŠŸ")
        return True
    except Exception as e:
        logger.error(f"âŒ åˆ†æå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        return False

@app.route('/login', methods=['GET', 'POST'])
def login():
    """ç™»å½•é¡µé¢"""
    auth_enabled, auth_config = check_auth_config()
    current_dir = os.path.dirname(os.path.abspath(__file__))
    template_path = os.path.join(current_dir, '..', 'templates', 'login.html')
    with open(template_path, 'r') as f:
        html_content = f.read()
    
    if not auth_enabled:
        return redirect(url_for('index'))
    
    if request.method == 'POST':
        password = request.form.get('password', '')
        config_password = auth_config.get('password', '')
        
        if not config_password:
            return render_template_string(html_content, 
                error="ç³»ç»Ÿæœªè®¾ç½®è®¿é—®å¯†ç ï¼Œè¯·è”ç³»ç®¡ç†å‘˜é…ç½®", 
                session_timeout=auth_config.get('session_timeout', 3600) // 60
            )
        
        if password == config_password:
            session['authenticated'] = True
            session['login_time'] = datetime.now().isoformat()
            logger.info("ç”¨æˆ·ç™»å½•æˆåŠŸ")
            return redirect(url_for('index'))
        else:
            logger.warning("ç”¨æˆ·ç™»å½•å¤±è´¥ï¼šå¯†ç é”™è¯¯")
            return render_template_string(html_content, 
                error="å¯†ç é”™è¯¯ï¼Œè¯·é‡è¯•", 
                session_timeout=auth_config.get('session_timeout', 3600) // 60
            )
    
    return render_template_string(html_content, 
        session_timeout=auth_config.get('session_timeout', 3600) // 60
    )

@app.route('/logout')
def logout():
    """é€€å‡ºç™»å½•"""
    session.pop('authenticated', None)
    session.pop('login_time', None)
    logger.info("ç”¨æˆ·é€€å‡ºç™»å½•")
    return redirect(url_for('login'))

@app.route('/')
@require_auth
def index():
    """ä¸»é¡µ"""
    auth_enabled, _ = check_auth_config()
    current_dir = os.path.dirname(os.path.abspath(__file__))
    template_path = os.path.join(current_dir, '..', 'templates', 'main.html')
    with open(template_path, 'r') as f:
        html_content = f.read()
    return render_template_string(html_content, auth_enabled=auth_enabled)

@app.route('/api/sse')
@require_auth
def sse_stream():
    """SSEæµæ¥å£"""
    client_id = request.args.get('client_id')
    if not client_id:
        return "Missing client_id", 400
    
    def event_stream():
        # åˆ›å»ºå®¢æˆ·ç«¯é˜Ÿåˆ—
        client_queue = Queue()
        sse_manager.add_client(client_id, client_queue)
        
        try:
            # å‘é€è¿æ¥ç¡®è®¤
            yield f"data: {json.dumps({'event': 'connected', 'data': {'client_id': client_id}})}\n\n"
            
            while True:
                try:
                    # è·å–æ¶ˆæ¯ï¼ˆå¸¦è¶…æ—¶ï¼Œé˜²æ­¢é•¿æ—¶é—´é˜»å¡ï¼‰
                    message = client_queue.get(timeout=30)
                    
                    # ç¡®ä¿æ¶ˆæ¯å¯ä»¥JSONåºåˆ—åŒ–
                    try:
                        json_data = json.dumps(message, ensure_ascii=False)
                        yield f"data: {json_data}\n\n"
                    except (TypeError, ValueError) as e:
                        logger.error(f"SSEæ¶ˆæ¯åºåˆ—åŒ–å¤±è´¥: {e}, æ¶ˆæ¯ç±»å‹: {type(message)}")
                        # å‘é€é”™è¯¯æ¶ˆæ¯
                        error_message = {
                            'event': 'error',
                            'data': {'error': f'æ¶ˆæ¯åºåˆ—åŒ–å¤±è´¥: {str(e)}'},
                            'timestamp': datetime.now().isoformat()
                        }
                        yield f"data: {json.dumps(error_message)}\n\n"
                        
                except Empty:
                    # å‘é€å¿ƒè·³
                    yield f"data: {json.dumps({'event': 'heartbeat', 'data': {'timestamp': datetime.now().isoformat()}})}\n\n"
                except GeneratorExit:
                    break
                except Exception as e:
                    logger.error(f"SSEæµå¤„ç†é”™è¯¯: {e}")
                    try:
                        error_message = {
                            'event': 'error',
                            'data': {'error': f'æµå¤„ç†é”™è¯¯: {str(e)}'},
                            'timestamp': datetime.now().isoformat()
                        }
                        yield f"data: {json.dumps(error_message)}\n\n"
                    except:
                        pass
                    break
                    
        except Exception as e:
            logger.error(f"SSEæµé”™è¯¯: {e}")
        finally:
            sse_manager.remove_client(client_id)
    
    return Response(
        event_stream(),
        mimetype='text/event-stream',
        headers={
            'Cache-Control': 'no-cache',
            'Connection': 'keep-alive',
            'Access-Control-Allow-Origin': '*',
        }
    )

class StreamingAnalyzer:
    """æµå¼åˆ†æå™¨"""
    
    def __init__(self, client_id):
        self.client_id = client_id
    
    def send_log(self, message, log_type='info'):
        """å‘é€æ—¥å¿—æ¶ˆæ¯"""
        sse_manager.send_to_client(self.client_id, 'log', {
            'message': message,
            'type': log_type
        })
    
    def send_progress(self, element_id, percent, message=None, current_stock=None):
        """å‘é€è¿›åº¦æ›´æ–°"""
        sse_manager.send_to_client(self.client_id, 'progress', {
            'element_id': element_id,
            'percent': percent,
            'message': message,
            'current_stock': current_stock
        })
    
    def send_scores(self, scores, animate=True):
        """å‘é€è¯„åˆ†æ›´æ–°"""
        sse_manager.send_to_client(self.client_id, 'scores_update', {
            'scores': scores,
            'animate': animate
        })
    
    def send_data_quality(self, data_quality):
        """å‘é€æ•°æ®è´¨é‡æŒ‡æ ‡"""
        sse_manager.send_to_client(self.client_id, 'data_quality_update', data_quality)
    
    def send_partial_result(self, data):
        """å‘é€éƒ¨åˆ†ç»“æœ"""
        cleaned_data = clean_data_for_json(data)
        sse_manager.send_to_client(self.client_id, 'partial_result', cleaned_data)
    
    def send_final_result(self, result):
        """å‘é€æœ€ç»ˆç»“æœ"""
        cleaned_result = clean_data_for_json(result)
        sse_manager.send_to_client(self.client_id, 'final_result', cleaned_result)
    
    def send_batch_result(self, results):
        """å‘é€æ‰¹é‡ç»“æœ"""
        cleaned_results = clean_data_for_json(results)
        sse_manager.send_to_client(self.client_id, 'batch_result', cleaned_results)
    
    def send_completion(self, message=None):
        """å‘é€å®Œæˆä¿¡å·"""
        sse_manager.send_to_client(self.client_id, 'analysis_complete', {
            'message': message or 'åˆ†æå®Œæˆ'
        })
    
    def send_error(self, error_message):
        """å‘é€é”™è¯¯ä¿¡æ¯"""
        sse_manager.send_to_client(self.client_id, 'analysis_error', {
            'error': error_message
        })
    
    def send_ai_stream(self, content):
        """å‘é€AIæµå¼å†…å®¹"""
        sse_manager.send_to_client(self.client_id, 'ai_stream', {
            'content': content
        })

def analyze_stock_streaming(stock_code, enable_streaming, client_id):
    """æµå¼è‚¡ç¥¨åˆ†æ"""
    streamer = StreamingAnalyzer(client_id)
    
    try:
        streamer.send_log(f"ğŸš€ å¼€å§‹æµå¼åˆ†æè‚¡ç¥¨: {stock_code}", 'header')
        streamer.send_progress('singleProgress', 5, "æ­£åœ¨è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯...")
        
        # è·å–è‚¡ç¥¨åç§°
        stock_name = analyzer.get_stock_name(stock_code)
        streamer.send_log(f"âœ“ è‚¡ç¥¨åç§°: {stock_name}", 'success')
        
        # å‘é€åŸºæœ¬ä¿¡æ¯
        streamer.send_partial_result({
            'type': 'basic_info',
            'stock_code': stock_code,
            'stock_name': stock_name,
            'current_price': 0,
            'price_change': 0
        })
        
        # 1. è·å–ä»·æ ¼æ•°æ®å’ŒæŠ€æœ¯åˆ†æ
        streamer.send_progress('singleProgress', 15, "æ­£åœ¨è·å–ä»·æ ¼æ•°æ®...")
        streamer.send_log("æ­£åœ¨è·å–å†å²ä»·æ ¼æ•°æ®...", 'info')
        
        price_data = analyzer.get_stock_data(stock_code)
        if price_data.empty:
            raise ValueError(f"æ— æ³•è·å–è‚¡ç¥¨ {stock_code} çš„ä»·æ ¼æ•°æ®")
        
        price_info = analyzer.get_price_info(price_data)
        streamer.send_log(f"âœ“ å½“å‰ä»·æ ¼: {price_info['current_price']:.2f}å…ƒ", 'success')
        
        # æ›´æ–°åŸºæœ¬ä¿¡æ¯
        streamer.send_partial_result({
            'type': 'basic_info',
            'stock_code': stock_code,
            'stock_name': stock_name,
            'current_price': price_info['current_price'],
            'price_change': price_info['price_change']
        })
        
        streamer.send_progress('singleProgress', 25, "æ­£åœ¨è®¡ç®—æŠ€æœ¯æŒ‡æ ‡...")
        technical_analysis = analyzer.calculate_technical_indicators(price_data)
        technical_score = analyzer.calculate_technical_score(technical_analysis)
        streamer.send_log(f"âœ“ æŠ€æœ¯åˆ†æå®Œæˆï¼Œå¾—åˆ†: {technical_score:.1f}", 'success')
        
        # å‘é€æŠ€æœ¯é¢å¾—åˆ†
        streamer.send_scores({
            'technical': technical_score,
            'fundamental': 50,
            'sentiment': 50,
            'comprehensive': 50
        })
        
        # 2. è·å–åŸºæœ¬é¢æ•°æ®
        streamer.send_progress('singleProgress', 45, "æ­£åœ¨åˆ†æè´¢åŠ¡æŒ‡æ ‡...")
        streamer.send_log("æ­£åœ¨è·å–25é¡¹è´¢åŠ¡æŒ‡æ ‡...", 'info')
        
        fundamental_data = analyzer.get_comprehensive_fundamental_data(stock_code)
        fundamental_score = analyzer.calculate_fundamental_score(fundamental_data)
        streamer.send_log(f"âœ“ åŸºæœ¬é¢åˆ†æå®Œæˆï¼Œå¾—åˆ†: {fundamental_score:.1f}", 'success')
        
        # å‘é€åŸºæœ¬é¢å¾—åˆ†
        streamer.send_scores({
            'technical': technical_score,
            'fundamental': fundamental_score,
            'sentiment': 50,
            'comprehensive': (technical_score + fundamental_score) / 2
        })
        
        # 3. è·å–æ–°é—»å’Œæƒ…ç»ªåˆ†æ
        streamer.send_progress('singleProgress', 65, "æ­£åœ¨åˆ†æå¸‚åœºæƒ…ç»ª...")
        streamer.send_log("æ­£åœ¨è·å–æ–°é—»æ•°æ®å’Œåˆ†æå¸‚åœºæƒ…ç»ª...", 'info')
        
        comprehensive_news_data = analyzer.get_comprehensive_news_data(stock_code, days=30)
        sentiment_analysis = analyzer.calculate_advanced_sentiment_analysis(comprehensive_news_data)
        sentiment_score = analyzer.calculate_sentiment_score(sentiment_analysis)
        streamer.send_log(f"âœ“ æƒ…ç»ªåˆ†æå®Œæˆï¼Œå¾—åˆ†: {sentiment_score:.1f}", 'success')
        
        # åˆå¹¶æ–°é—»æ•°æ®åˆ°æƒ…ç»ªåˆ†æç»“æœä¸­
        sentiment_analysis.update(comprehensive_news_data)
        
        # 4. è®¡ç®—ç»¼åˆå¾—åˆ†
        scores = {
            'technical': technical_score,
            'fundamental': fundamental_score,
            'sentiment': sentiment_score,
            'comprehensive': analyzer.calculate_comprehensive_score({
                'technical': technical_score,
                'fundamental': fundamental_score,
                'sentiment': sentiment_score
            })
        }
        
        # å‘é€æœ€ç»ˆå¾—åˆ†
        streamer.send_scores(scores, animate=True)
        
        # å‘é€æ•°æ®è´¨é‡æŒ‡æ ‡
        data_quality = {
            'financial_indicators_count': len(fundamental_data.get('financial_indicators', {})),
            'total_news_count': sentiment_analysis.get('total_analyzed', 0),
            'analysis_completeness': 'å®Œæ•´' if len(fundamental_data.get('financial_indicators', {})) >= 15 else 'éƒ¨åˆ†'
        }
        streamer.send_data_quality(data_quality)
        
        # 5. ç”ŸæˆæŠ•èµ„å»ºè®®
        streamer.send_progress('singleProgress', 80, "æ­£åœ¨ç”ŸæˆæŠ•èµ„å»ºè®®...")
        recommendation = analyzer.generate_recommendation(scores)
        streamer.send_log(f"âœ“ æŠ•èµ„å»ºè®®: {recommendation}", 'success')
        
        # 6. AIå¢å¼ºåˆ†æï¼ˆæµå¼ï¼‰
        streamer.send_progress('singleProgress', 90, "æ­£åœ¨è¿›è¡ŒAIæ·±åº¦åˆ†æ...")
        streamer.send_log("ğŸ¤– æ­£åœ¨è°ƒç”¨AIè¿›è¡Œæ·±åº¦åˆ†æ...", 'info')
        
        # è®¾ç½®AIæµå¼å†…å®¹å¤„ç†
        ai_content_buffer = ""
        
        def ai_stream_callback(content):
            """AIæµå¼å†…å®¹å›è°ƒ"""
            nonlocal ai_content_buffer
            ai_content_buffer += content
            # å®æ—¶å‘é€AIæµå¼å†…å®¹
            streamer.send_ai_stream(content)
        
        # æ‰§è¡ŒAIåˆ†æï¼Œæ”¯æŒæµå¼è¾“å‡º
        ai_analysis = analyzer.generate_ai_analysis({
            'stock_code': stock_code,
            'stock_name': stock_name,
            'price_info': price_info,
            'technical_analysis': technical_analysis,
            'fundamental_data': fundamental_data,
            'sentiment_analysis': sentiment_analysis,
            'scores': scores
        }, enable_streaming, ai_stream_callback)
        
        # å¦‚æœAIåˆ†æè¿”å›äº†å®Œæ•´å†…å®¹ï¼Œä½¿ç”¨è¿”å›çš„å†…å®¹ï¼Œå¦åˆ™ä½¿ç”¨ç¼“å†²çš„å†…å®¹
        if not ai_analysis and ai_content_buffer:
            ai_analysis = ai_content_buffer
        
        streamer.send_log("âœ… AIæ·±åº¦åˆ†æå®Œæˆ", 'success')
        
        # 7. ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        streamer.send_progress('singleProgress', 100, "åˆ†æå®Œæˆ")
        
        report = {
            'stock_code': stock_code,
            'stock_name': stock_name,
            'analysis_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'price_info': price_info,
            'technical_analysis': technical_analysis,
            'fundamental_data': fundamental_data,
            'comprehensive_news_data': comprehensive_news_data,
            'sentiment_analysis': sentiment_analysis,
            'scores': scores,
            'analysis_weights': analyzer.analysis_weights,
            'recommendation': recommendation,
            'ai_analysis': ai_analysis,
            'data_quality': data_quality
        }
        
        # å‘é€æœ€ç»ˆç»“æœ
        streamer.send_final_result(report)
        streamer.send_completion(f"âœ… {stock_code} æµå¼åˆ†æå®Œæˆï¼Œç»¼åˆå¾—åˆ†: {scores['comprehensive']:.1f}")
        
        return report
        
    except Exception as e:
        error_msg = f"æµå¼åˆ†æå¤±è´¥: {str(e)}"
        streamer.send_error(error_msg)
        streamer.send_log(f"âŒ {error_msg}", 'error')
        raise

def analyze_batch_streaming(stock_codes, client_id):
    """æµå¼æ‰¹é‡è‚¡ç¥¨åˆ†æ"""
    streamer = StreamingAnalyzer(client_id)
    
    try:
        total_stocks = len(stock_codes)
        streamer.send_log(f"ğŸ“Š å¼€å§‹æµå¼æ‰¹é‡åˆ†æ {total_stocks} åªè‚¡ç¥¨", 'header')
        
        results = []
        failed_stocks = []
        
        for i, stock_code in enumerate(stock_codes):
            try:
                progress = int((i / total_stocks) * 100)
                streamer.send_progress('batchProgress', progress, 
                    f"æ­£åœ¨åˆ†æç¬¬ {i+1}/{total_stocks} åªè‚¡ç¥¨", stock_code)
                
                streamer.send_log(f"ğŸ” å¼€å§‹åˆ†æ {stock_code} ({i+1}/{total_stocks})", 'info')
                
                # åˆ†æå•åªè‚¡ç¥¨ï¼ˆç®€åŒ–ç‰ˆï¼Œä¸å‘é€ä¸­é—´è¿›åº¦ï¼‰
                report = analyzer.analyze_stock(stock_code, False)
                results.append(report)
                
                streamer.send_log(f"âœ“ {stock_code} åˆ†æå®Œæˆ (å¾—åˆ†: {report['scores']['comprehensive']:.1f})", 'success')
                
            except Exception as e:
                failed_stocks.append(stock_code)
                streamer.send_log(f"âŒ {stock_code} åˆ†æå¤±è´¥: {e}", 'error')
        
        # è®¡ç®—å¹³å‡å¾—åˆ†å¹¶å‘é€
        if results:
            avg_scores = {
                'comprehensive': sum(r['scores']['comprehensive'] for r in results) / len(results),
                'technical': sum(r['scores']['technical'] for r in results) / len(results),
                'fundamental': sum(r['scores']['fundamental'] for r in results) / len(results),
                'sentiment': sum(r['scores']['sentiment'] for r in results) / len(results)
            }
            streamer.send_scores(avg_scores, animate=True)
            
            # å‘é€æ•°æ®è´¨é‡æŒ‡æ ‡
            avg_financial = sum(r['data_quality']['financial_indicators_count'] for r in results) / len(results)
            avg_news = sum(r['sentiment_analysis']['total_analyzed'] for r in results) / len(results)
            
            streamer.send_data_quality({
                'financial_indicators_count': round(avg_financial),
                'total_news_count': round(avg_news),
                'analysis_completeness': 'æ‰¹é‡'
            })
        
        streamer.send_progress('batchProgress', 100, f"æ‰¹é‡åˆ†æå®Œæˆ")
        
        # å‘é€æ‰¹é‡ç»“æœ
        streamer.send_batch_result(results)
        
        success_count = len(results)
        message = f"ğŸ‰ æ‰¹é‡åˆ†æå®Œæˆï¼æˆåŠŸåˆ†æ {success_count}/{total_stocks} åªè‚¡ç¥¨"
        if failed_stocks:
            message += f"ï¼Œå¤±è´¥: {', '.join(failed_stocks)}"
        
        streamer.send_completion(message)
        
        return results
        
    except Exception as e:
        error_msg = f"æ‰¹é‡æµå¼åˆ†æå¤±è´¥: {str(e)}"
        streamer.send_error(error_msg)
        streamer.send_log(f"âŒ {error_msg}", 'error')
        raise

@app.route('/api/analyze_stream', methods=['POST'])
@require_auth
def analyze_stock_stream():
    """å•åªè‚¡ç¥¨æµå¼åˆ†ææ¥å£"""
    try:
        if not analyzer:
            return jsonify({
                'success': False,
                'error': 'åˆ†æå™¨æœªåˆå§‹åŒ–'
            }), 500
        
        data = request.json
        stock_code = data.get('stock_code', '').strip()
        enable_streaming = data.get('enable_streaming', False)
        client_id = data.get('client_id')
        
        if not stock_code:
            return jsonify({
                'success': False,
                'error': 'è‚¡ç¥¨ä»£ç ä¸èƒ½ä¸ºç©º'
            }), 400
        
        if not client_id:
            return jsonify({
                'success': False,
                'error': 'ç¼ºå°‘å®¢æˆ·ç«¯ID'
            }), 400
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç›¸åŒçš„åˆ†ææ­£åœ¨è¿›è¡Œ
        with task_lock:
            if stock_code in analysis_tasks:
                return jsonify({
                    'success': False,
                    'error': f'è‚¡ç¥¨ {stock_code} æ­£åœ¨åˆ†æä¸­ï¼Œè¯·ç¨å€™'
                }), 429
            
            analysis_tasks[stock_code] = {
                'start_time': datetime.now(),
                'status': 'analyzing',
                'client_id': client_id
            }
        
        logger.info(f"å¼€å§‹æµå¼åˆ†æè‚¡ç¥¨: {stock_code}, å®¢æˆ·ç«¯: {client_id}")
        
        # å¼‚æ­¥æ‰§è¡Œåˆ†æ
        def run_analysis():
            try:
                global currentAnalysis
                report = analyze_stock_streaming(stock_code, enable_streaming, client_id)
                currentAnalysis = report
                logger.info(f"è‚¡ç¥¨æµå¼åˆ†æå®Œæˆ: {stock_code}")
            except Exception as e:
                logger.error(f"è‚¡ç¥¨æµå¼åˆ†æå¤±è´¥: {stock_code}, é”™è¯¯: {e}")
            finally:
                with task_lock:
                    analysis_tasks.pop(stock_code, None)
        
        # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œ
        executor.submit(run_analysis)
        
        return jsonify({
            'success': True,
            'message': f'è‚¡ç¥¨ {stock_code} æµå¼åˆ†æå·²å¯åŠ¨',
            'client_id': client_id
        })
        
    except Exception as e:
        logger.error(f"å¯åŠ¨è‚¡ç¥¨æµå¼åˆ†æå¤±è´¥: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/batch_analyze_stream', methods=['POST'])
@require_auth
def batch_analyze_stream():
    """æ‰¹é‡è‚¡ç¥¨æµå¼åˆ†ææ¥å£"""
    try:
        if not analyzer:
            return jsonify({
                'success': False,
                'error': 'åˆ†æå™¨æœªåˆå§‹åŒ–'
            }), 500
        
        data = request.json
        stock_codes = data.get('stock_codes', [])
        client_id = data.get('client_id')
        
        if not stock_codes:
            return jsonify({
                'success': False,
                'error': 'è‚¡ç¥¨ä»£ç åˆ—è¡¨ä¸èƒ½ä¸ºç©º'
            }), 400
        
        if not client_id:
            return jsonify({
                'success': False,
                'error': 'ç¼ºå°‘å®¢æˆ·ç«¯ID'
            }), 400
        
        # é™åˆ¶æ‰¹é‡åˆ†ææ•°é‡
        if len(stock_codes) > 10:
            return jsonify({
                'success': False,
                'error': 'æ‰¹é‡åˆ†ææœ€å¤šæ”¯æŒ10åªè‚¡ç¥¨'
            }), 400
        
        logger.info(f"å¼€å§‹æµå¼æ‰¹é‡åˆ†æ {len(stock_codes)} åªè‚¡ç¥¨, å®¢æˆ·ç«¯: {client_id}")
        
        # å¼‚æ­¥æ‰§è¡Œæ‰¹é‡åˆ†æ
        def run_batch_analysis():
            try:
                global currentAnalysis
                results = analyze_batch_streaming(stock_codes, client_id)
                currentAnalysis = results
                logger.info(f"æ‰¹é‡æµå¼åˆ†æå®Œæˆï¼ŒæˆåŠŸåˆ†æ {len(results)}/{len(stock_codes)} åªè‚¡ç¥¨")
            except Exception as e:
                logger.error(f"æ‰¹é‡æµå¼åˆ†æå¤±è´¥: {e}")
        
        # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œ
        executor.submit(run_batch_analysis)
        
        return jsonify({
            'success': True,
            'message': f'æ‰¹é‡åˆ†æå·²å¯åŠ¨ï¼Œå…± {len(stock_codes)} åªè‚¡ç¥¨',
            'client_id': client_id
        })
        
    except Exception as e:
        logger.error(f"å¯åŠ¨æ‰¹é‡æµå¼åˆ†æå¤±è´¥: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/status', methods=['GET'])
def status():
    """ç³»ç»ŸçŠ¶æ€æ£€æŸ¥"""
    try:
        auth_enabled, auth_config = check_auth_config()
        return jsonify({
            'success': True,
            'status': 'ready',
            'message': 'Webè‚¡ç¥¨åˆ†æç³»ç»Ÿè¿è¡Œæ­£å¸¸ (SSEæµå¼ç‰ˆ)',
            'analyzer_available': analyzer is not None,
            'auth_enabled': auth_enabled,
            'sse_support': True,
            'timestamp': datetime.now().isoformat()
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/analyze', methods=['POST'])
@require_auth
def analyze_stock():
    """å•åªè‚¡ç¥¨åˆ†æ - å…¼å®¹æ¥å£ï¼ˆéæµå¼ï¼‰"""
    try:
        if not analyzer:
            return jsonify({
                'success': False,
                'error': 'åˆ†æå™¨æœªåˆå§‹åŒ–'
            }), 500
        
        data = request.json
        stock_code = data.get('stock_code', '').strip()
        enable_streaming = data.get('enable_streaming', False)
        
        if not stock_code:
            return jsonify({
                'success': False,
                'error': 'è‚¡ç¥¨ä»£ç ä¸èƒ½ä¸ºç©º'
            }), 400
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç›¸åŒçš„åˆ†ææ­£åœ¨è¿›è¡Œ
        with task_lock:
            if stock_code in analysis_tasks:
                return jsonify({
                    'success': False,
                    'error': f'è‚¡ç¥¨ {stock_code} æ­£åœ¨åˆ†æä¸­ï¼Œè¯·ç¨å€™'
                }), 429
            
            analysis_tasks[stock_code] = {
                'start_time': datetime.now(),
                'status': 'analyzing'
            }
        
        logger.info(f"å¼€å§‹åˆ†æè‚¡ç¥¨: {stock_code}")
        
        try:
            # æ‰§è¡Œåˆ†æ
            report = analyzer.analyze_stock(stock_code, enable_streaming)
            
            # æ¸…ç†æ•°æ®ä¸­çš„NaNå€¼
            cleaned_report = clean_data_for_json(report)
            
            logger.info(f"è‚¡ç¥¨åˆ†æå®Œæˆ: {stock_code}")
            
            return jsonify({
                'success': True,
                'data': cleaned_report,
                'message': f'è‚¡ç¥¨ {stock_code} åˆ†æå®Œæˆ'
            })
            
        finally:
            with task_lock:
                analysis_tasks.pop(stock_code, None)
        
    except Exception as e:
        with task_lock:
            analysis_tasks.pop(stock_code, None)
        
        logger.error(f"è‚¡ç¥¨åˆ†æå¤±è´¥: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/batch_analyze', methods=['POST'])
@require_auth
def batch_analyze():
    """æ‰¹é‡è‚¡ç¥¨åˆ†æ - å…¼å®¹æ¥å£ï¼ˆéæµå¼ï¼‰"""
    try:
        if not analyzer:
            return jsonify({
                'success': False,
                'error': 'åˆ†æå™¨æœªåˆå§‹åŒ–'
            }), 500
        
        data = request.json
        stock_codes = data.get('stock_codes', [])
        
        if not stock_codes:
            return jsonify({
                'success': False,
                'error': 'è‚¡ç¥¨ä»£ç åˆ—è¡¨ä¸èƒ½ä¸ºç©º'
            }), 400
        
        if len(stock_codes) > 10:
            return jsonify({
                'success': False,
                'error': 'æ‰¹é‡åˆ†ææœ€å¤šæ”¯æŒ10åªè‚¡ç¥¨'
            }), 400
        
        logger.info(f"å¼€å§‹æ‰¹é‡åˆ†æ {len(stock_codes)} åªè‚¡ç¥¨")
        
        results = []
        failed_stocks = []
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘å¤„ç†
        futures = {}
        for stock_code in stock_codes:
            future = executor.submit(analyzer.analyze_stock, stock_code, False)
            futures[future] = stock_code
        
        # æ”¶é›†ç»“æœ
        for future in futures:
            stock_code = futures[future]
            try:
                report = future.result(timeout=60)
                results.append(report)
                logger.info(f"âœ“ {stock_code} åˆ†æå®Œæˆ")
            except Exception as e:
                failed_stocks.append(stock_code)
                logger.error(f"âŒ {stock_code} åˆ†æå¤±è´¥: {e}")
        
        # æ¸…ç†æ•°æ®ä¸­çš„NaNå€¼
        cleaned_results = clean_data_for_json(results)
        
        success_count = len(results)
        total_count = len(stock_codes)
        
        logger.info(f"æ‰¹é‡åˆ†æå®Œæˆï¼ŒæˆåŠŸåˆ†æ {success_count}/{total_count} åªè‚¡ç¥¨")
        
        response_data = {
            'success': True,
            'data': cleaned_results,
            'message': f'æ‰¹é‡åˆ†æå®Œæˆï¼ŒæˆåŠŸåˆ†æ {success_count}/{total_count} åªè‚¡ç¥¨'
        }
        
        if failed_stocks:
            response_data['failed_stocks'] = failed_stocks
            response_data['message'] += f'ï¼Œå¤±è´¥è‚¡ç¥¨: {", ".join(failed_stocks)}'
        
        return jsonify(response_data)
        
    except Exception as e:
        logger.error(f"æ‰¹é‡åˆ†æå¤±è´¥: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/task_status/<stock_code>', methods=['GET'])
@require_auth
def get_task_status(stock_code):
    """è·å–åˆ†æä»»åŠ¡çŠ¶æ€"""
    try:
        with task_lock:
            task_info = analysis_tasks.get(stock_code)
            
        if not task_info:
            return jsonify({
                'success': True,
                'status': 'not_found',
                'message': f'æœªæ‰¾åˆ°è‚¡ç¥¨ {stock_code} çš„åˆ†æä»»åŠ¡'
            })
        
        # è®¡ç®—åˆ†ææ—¶é•¿
        elapsed_time = (datetime.now() - task_info['start_time']).total_seconds()
        
        return jsonify({
            'success': True,
            'status': task_info['status'],
            'elapsed_time': elapsed_time,
            'client_id': task_info.get('client_id'),
            'message': f'è‚¡ç¥¨ {stock_code} æ­£åœ¨åˆ†æä¸­'
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/system_info', methods=['GET'])
def get_system_info():
    """è·å–ç³»ç»Ÿä¿¡æ¯"""
    try:
        with task_lock:
            active_tasks = len(analysis_tasks)
        
        with sse_lock:
            sse_clients_count = len(sse_manager.clients)
        
        # æ£€æµ‹é…ç½®çš„API
        configured_apis = []
        api_versions = {}
        
        if analyzer:
            for api_name, api_key in analyzer.api_keys.items():
                if api_name != 'notes' and api_key and api_key.strip():
                    configured_apis.append(api_name)
                    
                    # æ£€æµ‹APIç‰ˆæœ¬/çŠ¶æ€
                    if api_name == 'openai':
                        try:
                            import openai
                            if hasattr(openai, 'OpenAI'):
                                api_versions[api_name] = "æ–°ç‰ˆæœ¬"
                            else:
                                api_versions[api_name] = "æ—§ç‰ˆæœ¬"
                        except ImportError:
                            api_versions[api_name] = "æœªå®‰è£…"
                    elif api_name == 'anthropic':
                        try:
                            import anthropic
                            api_versions[api_name] = "å·²å®‰è£…"
                        except ImportError:
                            api_versions[api_name] = "æœªå®‰è£…"
                    elif api_name == 'zhipu':
                        try:
                            import zhipuai
                            api_versions[api_name] = "å·²å®‰è£…"
                        except ImportError:
                            api_versions[api_name] = "æœªå®‰è£…"
        
        # æ£€æµ‹é‰´æƒçŠ¶æ€
        auth_enabled, auth_config = check_auth_config()
        
        return jsonify({
            'success': True,
            'data': {
                'analyzer_available': analyzer is not None,
                'active_tasks': active_tasks,
                'max_workers': executor._max_workers,
                'sse_clients': sse_clients_count,
                'sse_support': True,
                'configured_apis': configured_apis,
                'api_versions': api_versions,
                'api_configured': len(configured_apis) > 0,
                'primary_api': analyzer.config.get('ai', {}).get('model_preference', 'openai') if analyzer else None,
                'auth_enabled': auth_enabled,
                'auth_configured': auth_config.get('password', '') != '',
                'version': 'Enhanced v3.0-Web-SSE',
                'timestamp': datetime.now().isoformat()
            }
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.errorhandler(404)
def not_found(error):
    return jsonify({
        'success': False,
        'error': 'æ¥å£ä¸å­˜åœ¨'
    }), 404

@app.errorhandler(500)
def internal_error(error):
    return jsonify({
        'success': False,
        'error': 'æœåŠ¡å™¨å†…éƒ¨é”™è¯¯'
    }), 500

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨Webç‰ˆç°ä»£è‚¡ç¥¨åˆ†æç³»ç»Ÿï¼ˆSSEæµå¼ç‰ˆï¼‰...")
    print("ğŸŒŠ Server-Sent Events | å®æ—¶æµå¼æ¨é€ | å®Œæ•´LLM APIæ”¯æŒ")
    print("=" * 70)
    
    # æ£€æŸ¥ä¾èµ–
    missing_deps = []
    
    try:
        import akshare
        print("   âœ… akshare: å·²å®‰è£…")
    except ImportError:
        missing_deps.append("akshare")
        print("   âŒ akshare: æœªå®‰è£…")
    
    try:
        import pandas
        print("   âœ… pandas: å·²å®‰è£…")
    except ImportError:
        missing_deps.append("pandas")
        print("   âŒ pandas: æœªå®‰è£…")
    
    try:
        import flask
        print("   âœ… flask: å·²å®‰è£…")
    except ImportError:
        missing_deps.append("flask")
        print("   âŒ flask: æœªå®‰è£…")
    
    try:
        import flask_cors
        print("   âœ… flask-cors: å·²å®‰è£…")
    except ImportError:
        missing_deps.append("flask-cors")
        print("   âŒ flask-cors: æœªå®‰è£…")
    
    # æ£€æŸ¥AIä¾èµ–
    ai_deps = []
    try:
        import openai
        if hasattr(openai, 'OpenAI'):
            ai_deps.append("OpenAI (æ–°ç‰ˆ)")
        else:
            ai_deps.append("OpenAI (æ—§ç‰ˆ)")
    except ImportError:
        pass
    
    try:
        import anthropic
        ai_deps.append("Claude")
    except ImportError:
        pass
    
    try:
        import zhipuai
        ai_deps.append("æ™ºè°±AI")
    except ImportError:
        pass
    
    if ai_deps:
        print(f"   ğŸ¤– AIæ”¯æŒ: {', '.join(ai_deps)}")
    else:
        print("   âš ï¸  AIä¾èµ–: æœªå®‰è£… (pip install openai anthropic zhipuai)")
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶
    if os.path.exists('config.json'):
        print("   âœ… config.json: å·²å­˜åœ¨")
        try:
            with open('config.json', 'r', encoding='utf-8') as f:
                config = json.load(f)
                api_keys = config.get('api_keys', {})
                configured_apis = [name for name, key in api_keys.items() 
                                 if name != 'notes' and key and key.strip()]
                if configured_apis:
                    print(f"   ğŸ”‘ å·²é…ç½®API: {', '.join(configured_apis)}")
                else:
                    print("   âš ï¸  APIå¯†é’¥: æœªé…ç½®")
                
                # æ£€æŸ¥Webé‰´æƒé…ç½®
                web_auth = config.get('web_auth', {})
                if web_auth.get('enabled', False):
                    if web_auth.get('password'):
                        print(f"   ğŸ” Webé‰´æƒ: å·²å¯ç”¨ (ä¼šè¯è¶…æ—¶: {web_auth.get('session_timeout', 3600)}ç§’)")
                    else:
                        print("   âš ï¸  Webé‰´æƒ: å·²å¯ç”¨ä½†æœªè®¾ç½®å¯†ç ")
                else:
                    print("   ğŸ”“ Webé‰´æƒ: æœªå¯ç”¨")
                    
        except Exception as e:
            print(f"   âŒ config.json: æ ¼å¼é”™è¯¯ - {e}")
    else:
        print("   âš ï¸  config.json: ä¸å­˜åœ¨ï¼Œå°†ä½¿ç”¨é»˜è®¤é…ç½®")
    
    if missing_deps:
        print(f"âŒ ç¼ºå°‘å¿…è¦ä¾èµ–: {', '.join(missing_deps)}")
        print(f"è¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…: pip install {' '.join(missing_deps)}")
        return
    
    print("=" * 70)
    
    # åˆå§‹åŒ–åˆ†æå™¨
    if not init_analyzer():
        print("âŒ åˆ†æå™¨åˆå§‹åŒ–å¤±è´¥ï¼Œç¨‹åºé€€å‡º")
        return
    
    print("âœ… ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼")
    print("ğŸŒŠ SSEæµå¼ç‰¹æ€§:")
    print("   - Server-Sent Events: æ”¯æŒ")
    print("   - å®æ—¶è¿›åº¦æ¨é€: å¯ç”¨")
    print("   - åŠ¨æ€ç»“æœæ›´æ–°: å¯ç”¨")
    print("   - å®¢æˆ·ç«¯è¿æ¥ç®¡ç†: è‡ªåŠ¨åŒ–")
    print("   - æ–­çº¿é‡è¿: è‡ªåŠ¨")
    print("   - å¿ƒè·³æ£€æµ‹: å¯ç”¨")
    
    print("ğŸ”¥ é«˜å¹¶å‘ç‰¹æ€§:")
    print(f"   - çº¿ç¨‹æ± : {executor._max_workers} ä¸ªå·¥ä½œçº¿ç¨‹")
    print("   - å¼‚æ­¥åˆ†æ: æ”¯æŒ")
    print("   - ä»»åŠ¡é˜Ÿåˆ—: æ”¯æŒ")
    print("   - é‡å¤è¯·æ±‚é˜²æŠ¤: å¯ç”¨")
    print("   - æ‰¹é‡å¹¶å‘ä¼˜åŒ–: å¯ç”¨")
    print("   - SSEè¿æ¥æ± : æ”¯æŒ")
    
    print("ğŸ” å®‰å…¨ç‰¹æ€§:")
    if analyzer:
        web_auth = analyzer.config.get('web_auth', {})
        if web_auth.get('enabled', False):
            if web_auth.get('password'):
                timeout_minutes = web_auth.get('session_timeout', 3600) // 60
                print(f"   - å¯†ç é‰´æƒ: å·²å¯ç”¨")
                print(f"   - ä¼šè¯è¶…æ—¶: {timeout_minutes} åˆ†é’Ÿ")
                print(f"   - å®‰å…¨çŠ¶æ€: ä¿æŠ¤æ¨¡å¼")
            else:
                print("   - å¯†ç é‰´æƒ: å·²å¯ç”¨ä½†æœªè®¾ç½®å¯†ç ")
                print("   - å®‰å…¨çŠ¶æ€: é…ç½®ä¸å®Œæ•´")
        else:
            print("   - å¯†ç é‰´æƒ: æœªå¯ç”¨")
            print("   - å®‰å…¨çŠ¶æ€: å¼€æ”¾æ¨¡å¼")
    else:
        print("   - é‰´æƒé…ç½®: æ— æ³•æ£€æµ‹")
    
    print("ğŸ¤– AIåˆ†æç‰¹æ€§:")
    if analyzer:
        api_keys = analyzer.api_keys
        configured_apis = [name for name, key in api_keys.items() 
                          if name != 'notes' and key and key.strip()]
        if configured_apis:
            print(f"   - å·²é…ç½®API: {', '.join(configured_apis)}")
            primary_api = analyzer.config.get('ai', {}).get('model_preference', 'openai')
            print(f"   - ä¸»è¦API: {primary_api}")
            
            api_base = analyzer.config.get('ai', {}).get('api_base_urls', {}).get('openai')
            if api_base and api_base != 'https://api.openai.com/v1':
                print(f"   - è‡ªå®šä¹‰APIåœ°å€: {api_base}")
            
            model = analyzer.config.get('ai', {}).get('models', {}).get(primary_api, 'default')
            print(f"   - ä½¿ç”¨æ¨¡å‹: {model}")
            
            print("   - LLMæ·±åº¦åˆ†æ: å®Œæ•´æ”¯æŒ")
            print("   - æµå¼AIæ¨ç†: æ”¯æŒ")
        else:
            print("   - APIé…ç½®: æœªé…ç½®")
            print("   - åˆ†ææ¨¡å¼: é«˜çº§è§„åˆ™åˆ†æ")
    else:
        print("   - åˆ†æå™¨: æœªåˆå§‹åŒ–")
    
    print("   - å¤šæ¨¡å‹æ”¯æŒ: OpenAI/Claude/æ™ºè°±AI")
    print("   - æ™ºèƒ½åˆ‡æ¢: å¯ç”¨")
    print("   - ç‰ˆæœ¬å…¼å®¹: æ–°æ—§ç‰ˆæœ¬è‡ªåŠ¨é€‚é…")
    print("   - è§„åˆ™åˆ†æå¤‡ç”¨: å¯ç”¨")
    
    print("ğŸ“‹ åˆ†æé…ç½®:")
    if analyzer:
        params = analyzer.analysis_params
        weights = analyzer.analysis_weights
        print(f"   - æŠ€æœ¯åˆ†æå‘¨æœŸ: {params.get('technical_period_days', 180)} å¤©")
        print(f"   - è´¢åŠ¡æŒ‡æ ‡æ•°é‡: {params.get('financial_indicators_count', 25)} é¡¹")
        print(f"   - æ–°é—»åˆ†ææ•°é‡: {params.get('max_news_count', 100)} æ¡")
        print(f"   - åˆ†ææƒé‡: æŠ€æœ¯{weights['technical']:.1f} | åŸºæœ¬é¢{weights['fundamental']:.1f} | æƒ…ç»ª{weights['sentiment']:.1f}")
    else:
        print("   - é…ç½®: ä½¿ç”¨é»˜è®¤å€¼")
    
    print("ğŸ“‹ æ€§èƒ½ä¼˜åŒ–:")
    print("   - æ—¥å¿—æ–‡ä»¶: å·²ç¦ç”¨")
    print("   - JSONå‹ç¼©: å¯ç”¨")
    print("   - ç¼“å­˜ä¼˜åŒ–: å¯ç”¨")
    print("   - NaNå€¼æ¸…ç†: å¯ç”¨")
    print("   - SSEæ¶ˆæ¯é˜Ÿåˆ—: å¯ç”¨")
    
    print("ğŸŒ WebæœåŠ¡å™¨å¯åŠ¨ä¸­...")
    print("ğŸ“± è¯·åœ¨æµè§ˆå™¨ä¸­è®¿é—®: http://localhost:5000")
    
    if analyzer and analyzer.config.get('web_auth', {}).get('enabled', False):
        print("ğŸ” é¦–æ¬¡è®¿é—®éœ€è¦å¯†ç éªŒè¯")
    
    print("ğŸ”§ APIæ¥å£æ–‡æ¡£:")
    print("   - GET  /api/status - ç³»ç»ŸçŠ¶æ€")
    print("   - GET  /api/sse?client_id=xxx - SSEæµå¼æ¥å£")
    print("   - POST /api/analyze_stream - å•åªè‚¡ç¥¨æµå¼åˆ†æ")
    print("   - POST /api/batch_analyze_stream - æ‰¹é‡è‚¡ç¥¨æµå¼åˆ†æ")
    print("   - POST /api/analyze - å•åªè‚¡ç¥¨åˆ†æ (å…¼å®¹)")
    print("   - POST /api/batch_analyze - æ‰¹é‡è‚¡ç¥¨åˆ†æ (å…¼å®¹)")
    print("   - GET  /api/task_status/<code> - ä»»åŠ¡çŠ¶æ€")
    print("   - GET  /api/system_info - ç³»ç»Ÿä¿¡æ¯")
    print("   - GET  /login - ç™»å½•é¡µé¢ (å¦‚å¯ç”¨é‰´æƒ)")
    print("   - GET  /logout - é€€å‡ºç™»å½•")
    print("ğŸŒŠ SSEäº‹ä»¶ç±»å‹:")
    print("   - connected: è¿æ¥ç¡®è®¤")
    print("   - log: æ—¥å¿—æ¶ˆæ¯")
    print("   - progress: è¿›åº¦æ›´æ–°")
    print("   - scores_update: è¯„åˆ†æ›´æ–°")
    print("   - data_quality_update: æ•°æ®è´¨é‡æ›´æ–°")
    print("   - partial_result: éƒ¨åˆ†ç»“æœ")
    print("   - final_result: æœ€ç»ˆç»“æœ")
    print("   - batch_result: æ‰¹é‡ç»“æœ")
    print("   - analysis_complete: åˆ†æå®Œæˆ")
    print("   - analysis_error: åˆ†æé”™è¯¯")
    print("   - heartbeat: å¿ƒè·³")
    print("=" * 70)
    
    # å¯åŠ¨FlaskæœåŠ¡å™¨
    try:
        app.run(
            host='0.0.0.0',
            port=5000,
            debug=False,
            threaded=True,
            use_reloader=False,
            processes=1
        )
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ç³»ç»Ÿå·²å…³é—­")
        executor.shutdown(wait=True)
    except Exception as e:
        print(f"âŒ æœåŠ¡å™¨å¯åŠ¨å¤±è´¥: {e}")
        executor.shutdown(wait=True)

if __name__ == '__main__':
    main()